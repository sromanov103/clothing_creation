# -*- coding: utf-8 -*-
"""clothing creation. Дз 35

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15gTU6XayaEyVMPuvh9DyWjXVgboqjbyi
"""

import tensorflow_datasets as tfds
from matplotlib import pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D , MaxPooling2D
from keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape, ReLU
import numpy as np
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy

ds = tf.keras.datasets.fashion_mnist
(train_images, _), (test_images, _) = ds.load_data()

SIZE = 28                  # линейный размер изображений (одно измерение)
INPUT_IMG = (SIZE, SIZE, 1) # размер входного изображений
BATCH_SIZE = 64             # размер пакета для обучения
LATENT_DIM = 100            # размерность латентного пространства

train_images = train_images.reshape(train_images.shape[0], *INPUT_IMG).astype('float32')
train_images = (train_images - 127.5) / 127.5

train_images.shape

print("Форма train_images:", train_images.shape)
print("Тип данных train_images:", train_images.dtype)

print(list(train_images[:1]))

print(len(train_images))

dataset=tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)

print(len(dataset))

import matplotlib.pyplot as plt

def plot_images(images, sqr = 5):
    plt.figure(figsize = (10,10))
    plt.title("Реальные изображения", fontsize = 35)
    for i in range(sqr * sqr):
        plt.subplot(sqr,sqr,i+1)
        plt.imshow(images[i], cmap='gray' )
        plt.axis('off')

# to plot images
plot_images(train_images, 6)

def discriminator_loss(fake_output, real_output):
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    return fake_loss + real_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Мы используем декоратор `tf.function`, можно и без него
# Он указывает на то, что функция должна быть скомпилирована, что оптимизирует процесс обучения.
# @tf.function
def train_steps(images, generator, discriminator):

    # генерируем шум на входе генератора
    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))

    # Инициализируем GradientTape (градиентную ленту) для дискриминатора и генератор
    #  по отдельности, чтобы записать операции,
    # выполняемые во время прямого прохода, включающего автодифференцирование.
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Запустим прямой проход шума через генератор.
        # Операции применяемые каждым слоем к своим
        # входным данным будут записаны на GradientTape, как на ленту магнитофона.
        # Отсюда и название градиентной ленты.
        generated_images = generator(noise)

        # Также обеспечиваем прямой проход через дискриминатор для
        # для реальных и фейковых изображений
        fake_output = discriminator(generated_images)
        real_output = discriminator(images)

        # расчитываем функции ошибок (значения потерь)
        gen_loss = generator_loss(fake_output)
        dis_loss = discriminator_loss(fake_output, real_output)

    # Используем gradient tape для автоматического извлечения градиентов
    # обучаемых переменных относительно потерь.
    gradient_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradient_of_discriminator = disc_tape.gradient(dis_loss, discriminator.trainable_variables)

    # Выполним один шаг градиентного спуска, обновив
    # значение переменных минимизирующих потери.
    optimizer_G.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))
    optimizer_D.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))

    # Вернем значения потерь для визуализации
    loss = {'gen_loss':gen_loss,
           'disc_loss': dis_loss}
    return loss

import time
def train(epochs, dataset, generator, discriminator):
    D_loss=[] # список для сбора значений потерь для дискриминатора
    G_loss=[] # список для сбора значений потерь для генератора
    for epoch in range(epochs):
        start = time.time()
        print("\nЭпоха : {}".format(epoch + 1))
        for images in dataset:

            loss = train_steps(images, generator, discriminator)
        print(" Время:{}".format(np.round(time.time() - start),2))
        print("Generator Loss: {} Discriminator Loss: {}".format(loss['gen_loss'],loss['disc_loss']))
        D_loss.append(loss['disc_loss'])
        G_loss.append(loss['gen_loss'])
    return (G_loss, D_loss)

"""#Архитектура сети

Генератор
"""

from tensorflow.keras import layers
def Generator():
    model = Sequential()

    model.add(Dense(7*7*128, input_shape=[LATENT_DIM]))
    model.add(BatchNormalization())
    model.add(ReLU())

    # Reshape для перехода в формат изображения
    model.add(Reshape((7,7, 128)))

    # model.add(Conv2DTranspose(128, 5, strides=(2,2), padding='same', kernel_initializer='he_normal'))
    # model.add(BatchNormalization())
    # model.add(ReLU())

    model.add(Conv2DTranspose(64, 5, strides=(2,2),  padding='same', kernel_initializer='he_normal'))
    model.add(BatchNormalization())
    model.add(ReLU())

    model.add(Conv2DTranspose(1, 5,strides=(2,2), padding='same', activation='tanh'))

    return model

from keras.models import Sequential
generator = Generator()
generator.summary()

"""Дискриминатор

"""

def Discriminator():
    model = tf.keras.Sequential()


    model.add(Conv2D(64, 4, strides=2, padding='same', input_shape=INPUT_IMG))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2D(128, 3, strides=2, padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Flatten())
    model.add(Dropout(0.3))
    model.add(Dense(1, activation = 'sigmoid'))

    return model

discriminator = Discriminator()
discriminator.summary()

noise = np.random.normal(-1,1,(1,LATENT_DIM))
img = generator(noise)
plt.imshow(img[0,:,:,0])
plt.show()

"""Определение функции потерть оптимизатора"""

optimizer_G = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
optimizer_D = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1=0.5)

# Этот метод возвращает вспомогательную функцию для вычисления перекрестных потерь энтропии
cross_entropy = tf.keras.losses.BinaryCrossentropy()

"""#Обучение"""

G, D = train(20, dataset, generator, discriminator )

def plot_generated_images(generator, square = 5):

  plt.figure(figsize = (10,10))
  for i in range(square * square):
    plt.subplot(square, square, i+1)
    noise = np.random.normal(0,1,(1,LATENT_DIM))
    img = generator(noise)
    plt.imshow(np.clip((img[0,...]+1)/2, 0, 1), cmap='gray')

    plt.axis('off')
    plt.grid()

plot_generated_images(generator, square=5)

def loss_plot(G, D):
    plt.figure(figsize=(10,10))
    plt.plot(G,color='red',label='Функция потерь на генераторе')
    plt.plot(D,color='blue',label='Функция потерь на дискриминаторе')
    plt.legend()
    plt.xlabel('Эпоха')
    plt.ylabel('Потери')
    plt.title('Функции потерь в конце обучения на эпохе')
    plt.show()
loss_plot(G, D)